{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Severstal: Steel Defect Detection.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNNHz52K0cLj3yV+h+SzVXY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sharjeelnawaz8182/Severstal-Steel-Defect-Detection-compitition/blob/main/Severstal_Steel_Defect_Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6lOMT2vRIvcP"
      },
      "source": [
        "import os\n",
        "import json\n",
        "import cv2\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "from keras import backend as K\n",
        "from keras.models import Model\n",
        "from keras.layers import Input\n",
        "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
        "from keras.layers.pooling import MaxPooling2D\n",
        "from keras.layers.merge import concatenate\n",
        "from keras.losses import binary_crossentropy\n",
        "from keras.callbacks import Callback, ModelCheckpoint\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from PIL import Image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qs7JvfuQ5e-r"
      },
      "source": [
        "def kuwahara_normal_filter(image,kernel=7):\n",
        "    pad_size = kernel//2\n",
        "    \n",
        "    height, width, channel = image.shape\n",
        "    out_image = image.copy()\n",
        "    \n",
        "    pad_image = np.zeros((height+pad_size*2,width+pad_size*2,channel))\n",
        "    for c in range(channel):\n",
        "        pad_image[:,:,c] = np.pad(out_image[:,:,c],[pad_size,pad_size],'constant')\n",
        "        \n",
        "    for h in range(height):\n",
        "        for w in range(width):\n",
        "            for c in range(channel):\n",
        "                #identify the area 1,2,3,4 range\n",
        "                #in pad image\n",
        "                cur_point_index = (h + pad_size,w + pad_size,c)\n",
        "                area = np.zeros((4,kernel//2 +1, kernel//2 +1))\n",
        "                \n",
        "                area[0] = pad_image[h:(cur_point_index[0]+1),w:(cur_point_index[1]+1),c]\n",
        "                area[1] = pad_image[h:(cur_point_index[0]+1),cur_point_index[1]:(cur_point_index[1]+pad_size+1),c]\n",
        "                area[2] = pad_image[cur_point_index[0]:(cur_point_index[0]+1+pad_size),w:(cur_point_index[1]+1),c]\n",
        "                area[3] = pad_image[cur_point_index[0]:(cur_point_index[0]+1+pad_size),cur_point_index[1]:(cur_point_index[1]+1+pad_size),c]\n",
        "                \n",
        "                \n",
        "                \n",
        "                std_area = [np.std(area[0]),np.std(area[1]),np.std(area[2]),np.std(area[3])]\n",
        "                min_std_area_index = np.argwhere(std_area==np.min(std_area))[0,0]\n",
        "             \n",
        "                out_image[h,w,c] = np.sum(area[min_std_area_index])/(len(area[min_std_area_index])**2)\n",
        "    return out_image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ltL6CVzUI6oY"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jxOmzNG1JAMU"
      },
      "source": [
        "image_path = \"/content/drive/MyDrive/compitition/severstal-steel-defect-detection\"\n",
        "import tensorflow as tf\n",
        "\n",
        "def loadImages(path):\n",
        "    '''Put files into lists and return them as one list with all images \n",
        "     in the folder'''\n",
        "    image_files = sorted([os.path.join(path, 'train_images', file)\n",
        "                          for file in os.listdir(path + \"/train_images\")\n",
        "                          if file.endswith('.jpg')])\n",
        "    return image_files\n",
        "def loadImagest(path):\n",
        "    '''Put files into lists and return them as one list with all images \n",
        "     in the folder'''\n",
        "    image_files = sorted([os.path.join(path, '1', file)\n",
        "                          for file in os.listdir(path + \"/1\")\n",
        "                          if file.endswith('.jpg')])\n",
        "    return image_files"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DgF8BpKIJOZn"
      },
      "source": [
        "def display_one(a, title1 = \"Original\"):\n",
        "    plt.imshow(a), plt.title(title1)\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iq-lclLGJIAk"
      },
      "source": [
        "dataset=loadImages(image_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gwHhm7PyMIla"
      },
      "source": [
        "dataset[4]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5i3xRfQz0ts_"
      },
      "source": [
        "train_df_original = pd.read_csv(\"/content/drive/MyDrive/compitition/severstal-steel-defect-detection/train.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3v0bI34C1eZ4"
      },
      "source": [
        "train_df_original.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VhgAS_dORrOF"
      },
      "source": [
        "TRAIN_PATH = '/content/drive/MyDrive/compitition/severstal-steel-defect-detection/train_images/'\n",
        "from glob import glob\n",
        "train_fns = pd.Series(sorted(glob(TRAIN_PATH + '*.jpg')))\n",
        "# train_fns.values\n",
        "train_fns_split = train_fns.str.split('/', expand=True)\n",
        "train_fns_split.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d-PSEjHCT0a9"
      },
      "source": [
        "from tqdm import tqdm\n",
        "train_df = pd.DataFrame(columns=['ImageId_ClassId','EncodedPixels'])\n",
        "# train_df.head()\n",
        "for i in tqdm(range(len(train_fns_split))):\n",
        "    for j in range(4):\n",
        "        tmp_se = pd.Series( [train_fns_split[7][i]+'_{}'.format(j+1),None], index=train_df.columns )\n",
        "        train_df = train_df.append( tmp_se, ignore_index=True )\n",
        "train_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T4H_ov_or-3J"
      },
      "source": [
        "for i in tqdm(range(len(train_df_original))):\n",
        "    imageid_classid = train_df_original['ImageId'][i]+'_{}'.format(train_df_original['ClassId'][i])\n",
        "    idx=train_df.query('ImageId_ClassId == \"{}\"'.format(imageid_classid)).index[0]\n",
        "    train_df['EncodedPixels'][idx] = train_df_original['EncodedPixels'][i]\n",
        "# print(train_df.shape)\n",
        "train_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2AgxXrVh-f04"
      },
      "source": [
        "train_df['image_id']=train_df['ImageId_ClassId'].apply(lambda x:x.split('_')[0])\n",
        "train_df['class_id']=train_df['ImageId_ClassId'].apply(lambda x:x.split('_')[1])\n",
        "train_df['has_defect'] = ~ train_df['EncodedPixels'].isna()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DBUXoPZqBnOj"
      },
      "source": [
        "train_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qp-IahqKfH-8"
      },
      "source": [
        "count_defect=train_df.groupby('image_id').agg(np.sum).reset_index()\n",
        "count_defect.sort_values('has_defect', ascending=False, inplace=True)\n",
        "# print(mask_count_df.shape)\n",
        "count_defect.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lMlcbYE2Ppbw"
      },
      "source": [
        "sub_df_original=pd.read_csv(\"/content/drive/MyDrive/compitition/severstal-steel-defect-detection/sample_submission.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o555jIcnQWYT"
      },
      "source": [
        "sub_df = pd.DataFrame(columns=['ImageId_ClassId','EncodedPixels'])\n",
        "for i in tqdm(range(len(sub_df_original))):\n",
        "    for j in range(4):\n",
        "        tmp_se = pd.Series( [sub_df_original['ImageId'][i]+'_{}'.format(j+1),None], index=sub_df.columns )\n",
        "        sub_df = sub_df.append( tmp_se, ignore_index=True )\n",
        "sub_df['ImageId'] = sub_df['ImageId_ClassId'].apply(lambda x: x.split('_')[0])\n",
        "sub_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jSlD1LttdF0g"
      },
      "source": [
        "len(train_df_original)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "slzSj__wM6LT"
      },
      "source": [
        "def mask2rle(img):\n",
        "    '''\n",
        "    img: numpy array, 1 - mask, 0 - background\n",
        "    Returns run length as string formated\n",
        "    '''\n",
        "    pixels= img.T.flatten()\n",
        "    pixels = np.concatenate([[0], pixels, [0]])\n",
        "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
        "    runs[1::2] -= runs[::2]\n",
        "    return ' '.join(str(x) for x in runs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i4bXkfu1NSnn"
      },
      "source": [
        "def rle2mask(mask_rle, shape=(256,1600)):\n",
        "    '''\n",
        "    mask_rle: run-length as string formated (start length)\n",
        "    shape: (width,height) of array to return \n",
        "    Returns numpy array, 1 - mask, 0 - background\n",
        "\n",
        "    '''\n",
        "    s = mask_rle.split()\n",
        "    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n",
        "    starts -= 1\n",
        "    ends = starts + lengths\n",
        "    img = np.zeros(shape[0]*shape[1],dtype=np.uint8)\n",
        "    for lo, hi in zip(starts, ends):\n",
        "        img[lo:hi] = 1\n",
        "    return img.reshape(shape).T"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6aszBvySVks_"
      },
      "source": [
        "def build_masks(rles, input_shape):\n",
        "    depth = len(rles)\n",
        "    height, width = input_shape\n",
        "    masks = np.zeros((height, width, depth))\n",
        "    for i, rle in enumerate(rles):\n",
        "        if type(rle) is str:\n",
        "            masks[:, :, i] = rle2mask(rle, (width, height))\n",
        "    return masks\n",
        "\n",
        "def build_rles(masks):\n",
        "    width, height, depth = masks.shape\n",
        "    \n",
        "    rles = [mask2rle(masks[:, :, i])\n",
        "            for i in range(depth)]\n",
        "    \n",
        "    return rles"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7_OQO_OxgEjP"
      },
      "source": [
        "def dice_coef(y_true, y_pred, smooth=1):\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersection = K.sum(y_true_f * y_pred_f)\n",
        "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ndfcfjwwgJRI"
      },
      "source": [
        "def dice_loss(y_true, y_pred):\n",
        "    smooth = 1.\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersection = y_true_f * y_pred_f\n",
        "    score = (2. * K.sum(intersection) + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
        "    return 1. - score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CBJ-xj82gPbx"
      },
      "source": [
        "def bce_dice_loss(y_true, y_pred):\n",
        "    return binary_crossentropy(y_true, y_pred) + dice_loss(y_true, y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ey-HcrsSoO4Y"
      },
      "source": [
        "pixel=np.ones((3,2))\n",
        "pixel=pixel.flatten()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_pV5T0G73xNK"
      },
      "source": [
        "train_df.head(40)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ujl0oXPo55DB"
      },
      "source": [
        "sample_filename = '0002cc93b.jpg'\n",
        "sample_image_df = train_df[train_df['image_id'] == sample_filename]\n",
        "sample_path =\"/content/drive/MyDrive/compitition/severstal-steel-defect-detection/train_images/{sample_image_df['image_id'].iloc[0]}\"\n",
        "im = cv2.imread(sample_path)\n",
        "sample_rles = sample_image_df['EncodedPixels'].values\n",
        "sample_masks = build_masks(sample_rles, input_shape=(256, 1600))\n",
        "\n",
        "for i in range(4):\n",
        "    display_one(sample_masks[:, :, i])\n",
        "    print(i)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4qj1eBe8Q6fa"
      },
      "source": [
        "def __load_grayscale():\n",
        "        image_path = \"/content/drive/MyDrive/compitition/severstal-steel-defect-detection/train_images\"\n",
        "        image_files = sorted([os.path.join(image_path, file)\n",
        "                          for file in os.listdir(image_path)\n",
        "                          if file.endswith('.jpg')])\n",
        "        for i, sample in enumerate(image_files):\n",
        "            item=sample\n",
        "            if(item.split('/')[7]==sample_image_df['image_id'].iloc[0]):\n",
        "              img = cv2.imread(sample, cv2.IMREAD_GRAYSCALE)\n",
        "              img = img.astype(np.float32) / 255.\n",
        "              img = np.expand_dims(img, axis=-1)\n",
        "\n",
        "        return img"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cqMjBmnIKYPJ"
      },
      "source": [
        "from google.colab.patches import cv2_imshow\n",
        "im=__load_grayscale()\n",
        "cv2_imshow(im)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9886P49vua5P"
      },
      "source": [
        "class DataGenerator(keras.utils.Sequence):\n",
        "    'Generates data for Keras'\n",
        "    def __init__(self, list_IDs, df, target_df=None, mode='fit',\n",
        "                 base_path=\"/content/drive/MyDrive/compitition/severstal-steel-defect-detection/train_images\"\n",
        "                 ,batch_size=32, dim=(256, 1600), n_channels=1,\n",
        "                 n_classes=4, random_state=2019, shuffle=True):\n",
        "        self.dim = dim\n",
        "        self.batch_size = batch_size\n",
        "        self.df = df\n",
        "        self.mode = mode\n",
        "        self.base_path = base_path\n",
        "        self.target_df = target_df\n",
        "        self.list_IDs = list_IDs\n",
        "        self.n_channels = n_channels\n",
        "        self.n_classes = n_classes\n",
        "        self.shuffle = shuffle\n",
        "        self.random_state = random_state\n",
        "        \n",
        "        self.on_epoch_end()\n",
        "\n",
        "    def __len__(self):\n",
        "        'Denotes the number of batches per epoch'\n",
        "        return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        'Generate one batch of data'\n",
        "        # Generate indexes of the batch\n",
        "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
        "\n",
        "        # Find list of IDs\n",
        "        list_IDs_batch = [self.list_IDs[k] for k in indexes]\n",
        "        \n",
        "        X = self.__generate_X(list_IDs_batch)\n",
        "        \n",
        "        if self.mode == 'fit':\n",
        "            y = self.__generate_y(list_IDs_batch)\n",
        "            return X, y\n",
        "        \n",
        "        elif self.mode == 'predict':\n",
        "            return X\n",
        "\n",
        "        else:\n",
        "            raise AttributeError('The mode parameter should be set to \"fit\" or \"predict\".')\n",
        "        \n",
        "    def on_epoch_end(self):\n",
        "        'Updates indexes after each epoch'\n",
        "        self.indexes = np.arange(len(self.list_IDs))\n",
        "        if self.shuffle == True:\n",
        "            np.random.seed(self.random_state)\n",
        "            np.random.shuffle(self.indexes)\n",
        "    \n",
        "    def __generate_X(self, list_IDs_batch):\n",
        "        'Generates data containing batch_size samples'\n",
        "        # Initialization\n",
        "        X = np.empty((self.batch_size, *self.dim, self.n_channels))\n",
        "        \n",
        "        # Generate data\n",
        "        for i, ID in enumerate(list_IDs_batch):\n",
        "            im_name = self.df['image_id'].iloc[ID]\n",
        "            img_path = \"{self.base_path}/{im_name}\"\n",
        "            img = self.__load_grayscale(im_name)\n",
        "            \n",
        "            # Store samples\n",
        "            X[i,] = img\n",
        "\n",
        "        return X\n",
        "    \n",
        "    def __generate_y(self, list_IDs_batch):\n",
        "        y = np.empty((self.batch_size, *self.dim, self.n_classes), dtype=int)\n",
        "        \n",
        "        for i, ID in enumerate(list_IDs_batch):\n",
        "            im_name = self.df['image_id'].iloc[ID]\n",
        "            image_df = self.target_df[self.target_df['image_id'] == im_name]\n",
        "            \n",
        "            rles = image_df['EncodedPixels'].values\n",
        "            masks = build_masks(rles, input_shape=self.dim)\n",
        "            \n",
        "            y[i, ] = masks\n",
        "\n",
        "        return y.astype(np.float32)\n",
        "    \n",
        "    def __load_grayscale(self, image_name):\n",
        "        image_path = \"/content/drive/MyDrive/compitition/severstal-steel-defect-detection/train_images\"\n",
        "        image_files = sorted([os.path.join(image_path, file)\n",
        "                          for file in os.listdir(image_path)\n",
        "                          if file.endswith('.jpg')])\n",
        "        for i, sample in enumerate(image_files):\n",
        "            item=sample\n",
        "            if(item.split('/')[7]==image_name):\n",
        "              img = cv2.imread(sample, cv2.IMREAD_GRAYSCALE)\n",
        "              img = img.astype(np.float32) / 255.\n",
        "              img = np.expand_dims(img, axis=-1)\n",
        "\n",
        "        return img\n",
        "    \n",
        "    def __load_rgb(self, img_path):\n",
        "        img = cv2.imread(img_path, cv2.COLOR_BGR2RGB)\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        img = img.astype(np.float32) / 255.\n",
        "\n",
        "        return img"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-9hq4Lz4G3R5"
      },
      "source": [
        "BATCH_SIZE = 16\n",
        "\n",
        "train_idx, val_idx = train_test_split(\n",
        "    count_defect.index, random_state=200, test_size=0.15\n",
        ")\n",
        "\n",
        "train_generator = DataGenerator(\n",
        "    train_idx, \n",
        "    df=count_defect,\n",
        "    target_df=train_df,\n",
        "    batch_size=BATCH_SIZE, \n",
        "    n_classes=4\n",
        ")\n",
        "\n",
        "val_generator = DataGenerator(\n",
        "    val_idx, \n",
        "    df=count_defect,\n",
        "    target_df=train_df,\n",
        "    batch_size=BATCH_SIZE, \n",
        "    n_classes=4\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cMGtSPSDH8Va"
      },
      "source": [
        "def build_model(input_shape):\n",
        "    inputs = Input(input_shape)\n",
        "\n",
        "    c1 = Conv2D(8, (3, 3), activation='elu', padding='same') (inputs)\n",
        "    c1 = Conv2D(8, (3, 3), activation='elu', padding='same') (c1)\n",
        "    p1 = MaxPooling2D((2, 2)) (c1)\n",
        "\n",
        "    c2 = Conv2D(16, (3, 3), activation='elu', padding='same') (p1)\n",
        "    c2 = Conv2D(16, (3, 3), activation='elu', padding='same') (c2)\n",
        "    p2 = MaxPooling2D((2, 2)) (c2)\n",
        "\n",
        "    c3 = Conv2D(32, (3, 3), activation='elu', padding='same') (p2)\n",
        "    c3 = Conv2D(32, (3, 3), activation='elu', padding='same') (c3)\n",
        "    p3 = MaxPooling2D((2, 2)) (c3)\n",
        "\n",
        "    c4 = Conv2D(64, (3, 3), activation='elu', padding='same') (p3)\n",
        "    c4 = Conv2D(64, (3, 3), activation='elu', padding='same') (c4)\n",
        "    p4 = MaxPooling2D(pool_size=(2, 2)) (c4)\n",
        "\n",
        "    c5 = Conv2D(64, (3, 3), activation='elu', padding='same') (p4)\n",
        "    c5 = Conv2D(64, (3, 3), activation='elu', padding='same') (c5)\n",
        "    p5 = MaxPooling2D(pool_size=(2, 2)) (c5)\n",
        "\n",
        "    c55 = Conv2D(128, (3, 3), activation='elu', padding='same') (p5)\n",
        "    c55 = Conv2D(128, (3, 3), activation='elu', padding='same') (c55)\n",
        "\n",
        "    u6 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same') (c55)\n",
        "    u6 = concatenate([u6, c5])\n",
        "    c6 = Conv2D(64, (3, 3), activation='elu', padding='same') (u6)\n",
        "    c6 = Conv2D(64, (3, 3), activation='elu', padding='same') (c6)\n",
        "\n",
        "    u71 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same') (c6)\n",
        "    u71 = concatenate([u71, c4])\n",
        "    c71 = Conv2D(32, (3, 3), activation='elu', padding='same') (u71)\n",
        "    c61 = Conv2D(32, (3, 3), activation='elu', padding='same') (c71)\n",
        "\n",
        "    u7 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same') (c61)\n",
        "    u7 = concatenate([u7, c3])\n",
        "    c7 = Conv2D(32, (3, 3), activation='elu', padding='same') (u7)\n",
        "    c7 = Conv2D(32, (3, 3), activation='elu', padding='same') (c7)\n",
        "\n",
        "    u8 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same') (c7)\n",
        "    u8 = concatenate([u8, c2])\n",
        "    c8 = Conv2D(16, (3, 3), activation='elu', padding='same') (u8)\n",
        "    c8 = Conv2D(16, (3, 3), activation='elu', padding='same') (c8)\n",
        "\n",
        "    u9 = Conv2DTranspose(8, (2, 2), strides=(2, 2), padding='same') (c8)\n",
        "    u9 = concatenate([u9, c1], axis=3)\n",
        "    c9 = Conv2D(8, (3, 3), activation='elu', padding='same') (u9)\n",
        "    c9 = Conv2D(8, (3, 3), activation='elu', padding='same') (c9)\n",
        "\n",
        "    outputs = Conv2D(4, (1, 1), activation='sigmoid') (c9)\n",
        "\n",
        "    model = Model(inputs=[inputs], outputs=[outputs])\n",
        "    model.compile(optimizer='adam', loss=bce_dice_loss, metrics=[dice_coef])\n",
        "    \n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yTHmiq3pID0X"
      },
      "source": [
        "model = build_model((256, 1600, 1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aSYufpBkjovd"
      },
      "source": [
        " checkpoint_path=\"/content/drive/MyDrive/compitition/severstal-steel-defect-detection/train_images/cp.ckpt\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hePy0z3x_6MX"
      },
      "source": [
        "model.load_weights(checkpoint_path)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sko88htVTYVw"
      },
      "source": [
        "checkpoint = ModelCheckpoint(\n",
        "    filepath=checkpoint_path, \n",
        "    monitor='val_dice_coef', \n",
        "    verbose=1, \n",
        "    save_weights_only=True,\n",
        "    save_best_only=True,\n",
        "    mode='auto'\n",
        ")\n",
        "\n",
        "history = model.fit_generator(\n",
        "    train_generator,\n",
        "    validation_data=val_generator,\n",
        "    callbacks=[checkpoint],\n",
        "    use_multiprocessing=True,\n",
        "    workers=1,\n",
        "    epochs=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "InfBHxJKUC3n"
      },
      "source": [
        "history_df = pd.DataFrame(history.history)\n",
        "history_df[['loss', 'val_loss']].plot()\n",
        "history_df[['dice_coef', 'val_dice_coef']].plot()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}